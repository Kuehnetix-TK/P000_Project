# ChatWithYourData â€“ Text2SQL Projekt ğŸ“Œ

## Ãœbersicht

Dieses Projekt wurde im Rahmen des Moduls "Projekt" an der DHBW Stuttgart entwickelt. Ziel ist es, eine Anwendung zu erstellen, die es Nutzer:innen ermÃ¶glicht, natÃ¼rliche Sprache zu verwenden, um SQL-Abfragen automatisch zu generieren und eine Datenbank abzufragen. Dazu wird ein Large Language Model (LLM) eingebunden, das Text â†’ SQL Ã¼bersetzt.

Das Projekt basiert auf dem Benchmark-Datensatz **BIRD-INTERACT (mini-interact)**. Die Hauptaufgabe besteht darin, die bereitgestellten Fragen korrekt zu beantworten, indem die Anwendung dynamisch SQL-Abfragen erzeugt und ausfÃ¼hrt.

## ğŸ¯ Projektziele

- Entwicklung eines funktionierenden Text2SQL-Prototyps
- Nutzung moderner LLM-Technologien zur automatischen SQL-Generierung
- Erstellung einer Architektur, die Frontend, Backend, LLM und Datenbank verbindet
- Umsetzung der im Modul geforderten Methoden des Software Engineerings, Projektmanagements und Teamarbeit

## ğŸ§  Motivation

Daten sind das Gold des 21. Jahrhunderts â€“ jedoch ist SQL fÃ¼r viele Mitarbeitende eine HÃ¼rde. Moderne KI-Modelle ermÃ¶glichen es, natÃ¼rliche Sprache effizient zu interpretieren.

Mit diesem Projekt helfen wir Unternehmen dabei, **data-driven** zu werden, indem wir die Distanz zwischen Mensch und Datenbank reduzieren.

## ğŸ› ï¸ Technologie-Stack

### Backend

- **Node.js / Express**
- Anbindung eines LLM (z. B. GPT-4.1, GPT-4o-mini, o3-mini, Claude 3.5 Sonnet)
- **SQLite** fÃ¼r den mini-interact Datensatz
- SQL Execution Layer

### Frontend

- Einfaches Chat-Interface (z. B. **React**)
- Anfrage â†’ Backend â†’ Antwortfluss

### Weitere Tools

- **GitHub** (Versionierung, Projektmanagement)
- ggf. **n8n** fÃ¼r explorative Low-Code-Prototypen

## ğŸ§ª Datensatz

- **Mini-Interact Benchmark Datensatz der BIRD-Initiative**
- **Fragen:** `mini_interact.jsonl` (instance_id: credit_1 â€“ credit_10)
- **Datenbank:** `credit.sqlite`

### Zusatzinfos:

- `credit_column_meaning_base.json`
- `credit_kb.jsonl`

**Wichtig:** Die offiziellen LÃ¶sungen liegen in Moodle und dÃ¼rfen nicht dem LLM zugÃ¤nglich gemacht werden.

## âš™ï¸ Funktionsweise

1. **Nutzer gibt natÃ¼rliche Sprache ein** â†’ z. B.  
   _â€Wie viele Kund:innen haben einen Kredit Ã¼ber 10.000 Euro?â€œ_

2. **Backend verarbeitet Eingabe**
   - Fragt LLM mit Schema + Prompt + Few-Shot-Beispielen an
   - LLM generiert SQL

3. **Backend fÃ¼hrt SQL aus**
   - SQLite-Abfrage

4. **Backend gibt Antwort zurÃ¼ck**
   - Ergebnis wird ins Frontend zurÃ¼ckgespielt

  ## ğŸ“ Architekturentscheidungen (ADR)

Beispielhafte Entscheidungen:

- Warum wir OpenAI/Claude als LLM gewÃ¤hlt haben
- Warum wir Few-Shot Prompting statt Fine-Tuning nutzen
- Wahl von Express.js statt Python FastAPI
- SicherheitsÃ¼berlegungen (kein Zugriff auf LÃ¶sungen)

## ğŸ§ª Tests

- **SQL-AusfÃ¼hrungstests**
- **Validierung der generierten Queries**
- **Evaluation der LLM-generierten Antworten**
- **Handling von Edge Cases** (invalid SQL, leere Antworten, etc.)

## ğŸš§ Bekannte Limitierungen

- LLM kann SQL halluzinieren
- Fehlende Kontextinformation â†’ komplexe Joins schwierig
- Performance abhÃ¤ngig vom LLM
- Kein Fine-Tuning auf BIRD-Datensatz

## ğŸš€ ErweiterungsmÃ¶glichkeiten

- UnterstÃ¼tzung mehrerer Datenbanken (DB-Auswahlproblem lÃ¶sen)
- Automatisierte Schema-Extraktion
- SQL-Korrektur mittels Self-Refinement
- Integration Open-Source-LLMs (Llama 3.1 / Qwen / DeepSeek) via Ollama
- Low-Code Automation Layer mit n8n

## ğŸ“… Projektmanagement-Komponenten

- **GruppengrÃ¶ÃŸe:** ~5 Studierende
- **Tickets zu:** Frontend, Backend, LLM-Anbindung, Testing, Evaluation, Doku
- **RegelmÃ¤ÃŸige Sprint Reviews**
- **Nutzung eines Kanban-Boards**
- **AbschlussprÃ¤sentation:** 20 Min + 10 Min Q&A

## ğŸ§­ Selbstreflexion (fÃ¼r die Abgabe)

- Was lief gut?
- Was hat nicht gut funktioniert?
- Wie kÃ¶nnte man im nÃ¤chsten Projekt besser zusammenarbeiten?
- Welche Rolle habe ich im Team eingenommen?

## ğŸ“– Lizenz

Dieses Projekt dient ausschlieÃŸlich zu Studienzwecken an der DHBW Stuttgart.

## ğŸ‘¥ Team

Tim KÃ¼hne, Dominik Ruoff, Joel Martinez, Umut Polat, SÃ¶ren Frank
